[
    {
        "index": 0,
        "reasoning": "We are given 96 hourly data points for the \"High UseLess Load\" (HULL) from 2017-04-03 00:00:00 to 2017-04-06 23:00:00.\n The task is to forecast the next 96 hours (from 2017-04-07 00:00:00 to 2017-04-10 23:00:00).\n\n However, note that the data has missing values? The provided data does not have any missing values in the given 96 points.\n But the problem says \"these data will have missing values\", so we must be cautious. Since the provided 96 points are complete, we can proceed.\n\n Steps:\n 1. We note that the data is hourly and has a daily pattern (24-hour cycle). We can use a time series model that captures seasonality.\n 2. Given the small data size (only 4 days) and the requirement to forecast 4 days, we can use a model like SARIMA or Exponential Smoothing (ETS) with seasonality.\n 3. However, due to the very short history, we might also consider simpler methods like using the average of the same hour in the past days, or a seasonal naive method.\n\n But note: the problem says the data has missing values. Since the provided 96 points are complete, we assume that the missing values are in the past and we are to forecast the next 96 without missing.\n\n However, the problem does not specify the frequency of missing values. Since we are only given 96 complete points, we will use these to forecast.\n\n Approach:\n We will use a seasonal decomposition and then forecast the seasonal component. Given the short history, we can compute the average pattern for 24 hours and then repeat it for 4 days.\n\n Steps for a simple method:\n  - Group the data by hour of the day (0 to 23) and compute the average for each hour.\n  - Then, for the next 96 hours (4 days), we use the average of the corresponding hour.\n\n However, note that the data might have a trend? Let's check the provided data:\n\n  The data from 2017-04-03 to 2017-04-06:\n\n  We can see a daily pattern: \n    - During the day (e.g., 8:00 to 15:00) we see higher values (like 2.478, 2.947, 4.019) and then negative values at night.\n\n  But looking at the last day (2017-04-06) we see:\n      00:00:00  0.134\n      01:00:00  0.067\n      ... \n      22:00:00 -0.536\n      23:00:00  0.737\n\n  We can compute the hourly average:\n\n  Let's create a table for each hour (0 to 23) and average the 4 days? But note: we have exactly 4 days? \n  From 2017-04-03 to 2017-04-06: that's 4 days? \n      Day 1: 2017-04-03 (Monday) -> 24 hours\n      Day 2: 2017-04-04 (Tuesday) -> 24 hours\n      Day 3: 2017-04-05 (Wednesday) -> 24 hours\n      Day 4: 2017-04-06 (Thursday) -> 24 hours\n\n  So we have 4 days. We can average each hour across these 4 days.\n\n  However, note that the pattern might change by day of the week? But we only have 4 days (Monday to Thursday) and we are forecasting the next 4 days (Friday, Saturday, Sunday, Monday). \n  The next 96 hours would be:\n      2017-04-07 (Friday) 00:00:00 to 23:00:00\n      2017-04-08 (Saturday) 00:00:00 to 23:00:00\n      2017-04-09 (Sunday) 00:00:00 to 23:00:00\n      2017-04-10 (Monday) 00:00:00 to 23:00:00\n\n  Since we don't have data for Friday, Saturday, Sunday, we cannot use the same hour of the same day of the week. Therefore, we use the overall average for each hour.\n\n  Alternatively, we can use the last available day (Thursday) for Friday? But that might not be accurate.\n\n  Given the lack of data, the safest is to use the average of the 4 days for each hour.\n\n  Steps:\n    - Extract the hour from the datetime.\n    - Group by hour and compute the mean.\n\n  Example for hour 0:\n      2017-04-03 00:00:00: 0.469\n      2017-04-04 00:00:00: 1.072\n      2017-04-05 00:00:00: -0.201\n      2017-04-06 00:00:00: 0.134\n      Average = (0.469 + 1.072 - 0.201 + 0.134) / 4 = (1.474) / 4 = 0.3685\n\n  We do this for each hour.\n\n  Then, for the next 96 hours (4 days) we assign:\n      Day 1 (2017-04-07): hour0, hour1, ... hour23 -> [avg0, avg1, ... avg23]\n      Day 2 (2017-04-08): same as above\n      Day 3 (2017-04-09): same\n      Day 4 (2017-04-10): same\n\n  But note: the problem says the data will have missing values. We are not given any missing in the history, but for the forecast we are to provide complete data.\n\n  However, this method does not account for any trend. We can check if there is a trend by looking at the daily average:\n\n      Day1 (2017-04-03): average = (sum of 24 values) -> let's compute quickly:\n          0.469, 1.541, 2.210, 1.072, 1.206, 1.005, 0.335, 0.670, 2.478, 2.947, 4.019, 1.808, 1.005, 3.885, 4.019, 1.139, -0.335, -0.335, -1.072, -0.871, -0.804, -1.541, -0.603, 0.067\n          Sum = 0.469+1.541+2.210+1.072+1.206+1.005+0.335+0.670+2.478+2.947+4.019+1.808+1.005+3.885+4.019+1.139-0.335-0.335-1.072-0.871-0.804-1.541-0.603+0.067\n          = 0.469+1.541=2.01; +2.210=4.22; +1.072=5.292; +1.206=6.498; +1.005=7.503; +0.335=7.838; +0.670=8.508; +2.478=10.986; +2.947=13.933; +4.019=17.952; +1.808=19.76; +1.005=20.765; +3.885=24.65; +4.019=28.669; +1.139=29.808; then negatives: -0.335*2 = -0.67 -> 29.808-0.67=29.138; -1.072=28.066; -0.871=27.195; -0.804=26.391; -1.541=24.85; -0.603=24.247; +0.067=24.314.\n          Average for day1 = 24.314 / 24 = 1.013\n\n      Day2: 2017-04-04: \n          1.072,0.067,0.938,0.737,-0.536,0.000,0.067,-0.402,0.000,0.000,0.000,2.143,-0.536,0.536,-0.335,-0.670,-1.139,-0.938,-1.808,-2.009,-1.808,-1.474,-0.134,-0.067\n          Sum = 1.072+0.067=1.139; +0.938=2.077; +0.737=2.814; -0.536=2.278; +0=2.278; +0.067=2.345; -0.402=1.943; +0=1.943; +0=1.943; +0=1.943; +2.143=4.086; -0.536=3.55; +0.536=4.086; -0.335=3.751; -0.670=3.081; -1.139=1.942; -0.938=1.004; -1.808=-0.804; -2.009=-2.813; -1.808=-4.621; -1.474=-6.095; -0.134=-6.229; -0.067=-6.296\n          Average = -6.296/24 = -0.2623\n\n      Day3: 2017-04-05:\n          -0.201,0.469,-0.134,0.335,0.670,0.000,0.201,1.072,1.072,0.134,0.268,-0.067,-0.804,-0.268,-0.134,-0.402,-1.072,-0.670,-1.139,-1.139,-1.139,-1.139,-1.407,0.000\n          Sum = -0.201+0.469=0.268; -0.134=0.134; +0.335=0.469; +0.670=1.139; +0=1.139; +0.201=1.34; +1.072=2.412; +1.072=3.484; +0.134=3.618; +0.268=3.886; -0.067=3.819; -0.804=3.015; -0.268=2.747; -0.134=2.613; -0.402=2.211; -1.072=1.139; -0.670=0.469; -1.139=-0.67; -1.139=-1.809; -1.139=-2.948; -1.139=-4.087; -1.407=-5.494; +0=-5.494\n          Average = -5.494/24 = -0.2289\n\n      Day4: 2017-04-06:\n          0.134,0.067,0.804,0.268,0.268,1.139,0.201,-0.737,-0.268,0.000,0.603,0.469,-0.335,0.670,0.201,0.000,0.000,-0.201,-0.804,-1.072,-1.005,-1.674,-0.536,0.737\n          Sum = 0.134+0.067=0.201; +0.804=1.005; +0.268=1.273; +0.268=1.541; +1.139=2.68; +0.201=2.881; -0.737=2.144; -0.268=1.876; +0=1.876; +0.603=2.479; +0.469=2.948; -0.335=2.613; +0.670=3.283; +0.201=3.484; +0=3.484; +0=3.484; -0.201=3.283; -0.804=2.479; -1.072=1.407; -1.005=0.402; -1.674=-1.272; -0.536=-1.808; +0.737=-1.071\n          Average = -1.071/24 = -0.0446\n\n  The daily averages are: 1.013, -0.2623, -0.2289, -0.0446 -> no clear trend? It went down and then up slightly.\n\n  Therefore, we can use the hourly average without detrending.\n\n  Let's compute the hourly averages:\n\n  We'll create a list for each hour (0 to 23) and average the 4 values.\n\n  Hour 0: [0.469, 1.072, -0.201, 0.134] -> (0.474) -> 0.474/4 = 0.1185? Actually: 0.469+1.072=1.541; 1.541-0.201=1.34; 1.34+0.134=1.474 -> 1.474/4 = 0.3685\n  Hour 1: [1.541, 0.067, 0.469, 0.067] -> 1.541+0.067=1.608; +0.469=2.077; +0.067=2.144 -> 2.144/4=0.536\n  Hour 2: [2.210, 0.938, -0.134, 0.804] -> 2.210+0.938=3.148; -0.134=3.014; +0.804=3.818 -> 3.818/4=0.9545\n  Hour 3: [1.072, 0.737, 0.335, 0.268] -> 1.072+0.737=1.809; +0.335=2.144; +0.268=2.412 -> 2.412/4=0.603\n  Hour 4: [1.206, -0.536, 0.670, 0.268] -> 1.206-0.536=0.67; +0.670=1.34; +0.268=1.608 -> 1.608/4=0.402\n  Hour 5: [1.005, 0.000, 0.000, 1.139] -> 1.005+0+0+1.139=2.144 -> 2.144/4=0.536\n  Hour 6: [0.335, 0.067, 0.201, 0.201] -> 0.335+0.067=0.402; +0.201=0.603; +0.201=0.804 -> 0.804/4=0.201\n  Hour 7: [0.670, -0.402, 1.072, -0.737] -> 0.670-0.402=0.268; +1.072=1.34; -0.737=0.603 -> 0.603/4=0.15075\n  Hour 8: [2.478, 0.000, 1.072, -0.268] -> 2.478+0=2.478; +1.072=3.55; -0.268=3.282 -> 3.282/4=0.8205\n  Hour 9: [2.947, 0.000, 0.134, 0.000] -> 2.947+0+0.134+0=3.081 -> 3.081/4=0.77025\n  Hour 10: [4.019, 0.000, 0.268, 0.603] -> 4.019+0=4.019; +0.268=4.287; +0.603=4.89 -> 4.89/4=1.2225\n  Hour 11: [1.808, 2.143, -0.067, 0.469] -> 1.808+2.143=3.951; -0.067=3.884; +0.469=4.353 -> 4.353/4=1.08825\n  Hour 12: [1.005, -0.536, -0.804, -0.335] -> 1.005-0.536=0.469; -0.804=-0.335; -0.335=-0.67 -> -0.67/4=-0.1675\n  Hour 13: [3.885, 0.536, -0.268, 0.670] -> 3.885+0.536=4.421; -0.268=4.153; +0.670=4.823 -> 4.823/4=1.20575\n  Hour 14: [4.019, -0.335, -0.134, 0.201] -> 4.019-0.335=3.684; -0.134=3.55; +0.201=3.751 -> 3.751/4=0.93775\n  Hour 15: [1.139, -0.670, -0.402, 0.000] -> 1.139-0.670=0.469; -0.402=0.067; +0=0.067 -> 0.067/4=0.01675\n  Hour 16: [-0.335, -1.139, -1.072, 0.000] -> -0.335-1.139=-1.474; -1.072=-2.546; +0=-2.546 -> -2.546/4=-0.6365\n  Hour 17: [-0.335, -0.938, -0.670, -0.201] -> -0.335-0.938=-1.273; -0.670=-1.943; -0.201=-2.144 -> -2.144/4=-0.536\n  Hour 18: [-1.072, -1.808, -1.139, -0.804] -> -1.072-1.808=-2.88; -1.139=-4.019; -0.804=-4.823 -> -4.823/4=-1.20575\n  Hour 19: [-0.871, -2.009, -1.139, -1.072] -> -0.871-2.009=-2.88; -1.139=-4.019; -1.072=-5.091 -> -5.091/4=-1.27275\n  Hour 20: [-0.804, -1.808, -1.139, -1.005] -> -0.804-1.808=-2.612; -1.139=-3.751; -1.005=-4.756 -> -4.756/4=-1.189\n  Hour 21: [-1.541, -1.474, -1.139, -1.674] -> -1.541-1.474=-3.015; -1.139=-4.154; -1.674=-5.828 -> -5.828/4=-1.457\n  Hour 22: [-0.603, -0.134, -1.407, -0.536] -> -0.603-0.134=-0.737; -1.407=-2.144; -0.536=-2.68 -> -2.68/4=-0.67\n  Hour 23: [0.067, -0.067, 0.000, 0.737] -> 0.067-0.067=0; +0=0; +0.737=0.737 -> 0.737/4=0.18425\n\n  Now, we create the next 96 hours:\n\n  Start from 2017-04-07 00:00:00 (which is the next hour after 2017-04-06 23:00:00) and go for 96 hours.\n\n  We'll generate the dates:\n\n      Day 5: 2017-04-07 (Friday) -> hours 0 to 23: use the average for hour0, hour1, ... hour23 as above.\n      Day 6: 2017-04-08 (Saturday) -> same pattern\n      Day 7: 2017-04-09 (Sunday) -> same pattern\n      Day 8: 2017-04-10 (Monday) -> same pattern\n\n  But note: the problem says the data might have missing values? We are to provide complete data. So we output 96 lines.\n\n  We'll round the numbers to 3 decimal places as in the input.\n\n  However, note: the input data has up to 3 decimal places.\n\n  Let's write the forecast:\n\n  Hour 0: 0.3685 -> 0.369 (rounded to 3 decimals)\n  Hour 1: 0.536 -> 0.536\n  Hour 2: 0.9545 -> 0.955\n  ... and so on.\n\n  But note: the problem says \"You must provide the complete data\" and \"You mustn't omit any content\". So we output 96 lines.\n\n  We'll generate the dates:\n\n      Start: 2017-04-07 00:00:00\n      Then 2017-04-07 01:00:00, ... up to 2017-04-10 23:00:00.\n\n  We'll create a list of dates and then assign the average value for the corresponding hour.\n\n  Code for generating the dates:\n\n      from datetime import datetime, timedelta\n      start = datetime(2017,4,7,0,0,0)\n      dates = [start + timedelta(hours=i) for i in range(96)]\n\n  But we are not coding, we are writing the output.\n\n  We'll write 96 lines.\n\n  However, note: the problem says the data will have missing values? We are not given any in the history, and we are to forecast without missing.\n\n  So we output the 96 points.\n\n  Let's write the data:\n\n  We have to be careful: the rounding.\n\n  We'll compute the hourly averages and round to 3 decimals:\n\n      Hour0: 0.3685 -> 0.369\n      Hour1: 0.536 -> 0.536\n      Hour2: 0.9545 -> 0.955\n      Hour3: 0.603 -> 0.603\n      Hour4: 0.402 -> 0.402\n      Hour5: 0.536 -> 0.536\n      Hour6: 0.201 -> 0.201\n      Hour7: 0.15075 -> 0.151\n      Hour8: 0.8205 -> 0.821\n      Hour9: 0.77025 -> 0.770\n      Hour10: 1.2225 -> 1.223\n      Hour11: 1.08825 -> 1.088\n      Hour12: -0.1675 -> -0.168\n      Hour13: 1.20575 -> 1.206\n      Hour14: 0.93775 -> 0.938\n      Hour15: 0.01675 -> 0.017\n      Hour16: -0.6365 -> -0.637\n      Hour17: -0.536 -> -0.536\n      Hour18: -1.20575 -> -1.206\n      Hour19: -1.27275 -> -1.273\n      Hour20: -1.189 -> -1.189\n      Hour21: -1.457 -> -1.457\n      Hour22: -0.67 -> -0.670\n      Hour23: 0.18425 -> 0.184\n\n  Then for each day we repeat these 24 values.\n\n  So the first day (2017-04-07) will be:\n\n      2017-04-07 00:00:00  0.369\n      2017-04-07 01:00:00  0.536\n      2017-04-07 02:00:00  0.955\n      2017-04-07 03:00:00  0.603\n      2017-04-07 04:00:00  0.402\n      2017-04-07 05:00:00  0.536\n      2017-04-07 06:00:00  0.201\n      2017-04-07 07:00:00  0.151\n      2017-04-07 08:00:00  0.821\n      2017-04-07 09:00:00  0.770\n      2017-04-07 10:00:00  1.223\n      2017-04-07 11:00:00  1.088\n      2017-04-07 12:00:00 -0.168\n      2017-04-07 13:00:00  1.206\n      2017-04-07 14:00:00  0.938\n      2017-04-07 15:00:00  0.017\n      2017-04-07 16:00:00 -0.637\n      2017-04-07 17:00:00 -0.536\n      2017-04-07 18:00:00 -1.206\n      2017-04-07 19:00:00 -1.273\n      2017-04-07 20:00:00 -1.189\n      2017-04-07 21:00:00 -1.457\n      2017-04-07 22:00:00 -0.670\n      2017-04-07 23:00:00  0.184\n\n  Then the next day (2017-04-08) same 24 values, and so on.\n\n  We'll write 4 days.\n\n  But note: the problem says the data might have missing values? We are providing a complete forecast.\n\n  We output in the same format as the input: two columns, with the date in the format \"YYYY-MM-DD HH:MM:SS\" and the HULL value.\n\n  We must output 96 lines.\n\n  Let's write the answer in the required XML-like tag.\n\n  Important: The problem says \"You must provide the complete data. You mustn't omit any content.\"\n\n  We'll write:\n\n      <answer>\n          date   HULL\n          2017-04-07 00:00:00  0.369\n          2017-04-07 01:00:00  0.536\n          ... \n          2017-04-10 23:00:00  0.184   [but note: the last hour is hour23, which is 0.184]\n\n  However, note: the last hour of the last day (2017-04-10 23:00:00) should be the same as the hour23 value.\n\n  We'll generate:\n\n      Day1: 2017-04-07: 24 lines\n      Day2: 2017-04-08: 24 lines\n      Day3: 2017-04-09: 24 lines\n      Day4: 2017-04-10: 24 lines\n\n  Total 96.\n\n  We'll write the data without the index (like the input).\n\n  Format:\n\n        date   HULL\n        2017-04-07 00:00:00  0.369\n        ...\n\n  But note: the input had a space between the date and the value? Actually, the input had:\n\n        \"2017-04-03 00:00:00  0.469\"\n\n  We'll use two spaces to separate.\n\n  Alternatively, we can use a tab? The input used multiple spaces. We'll use a single space.\n\n  Actually, the input had:\n\n        \"2017-04-03 00:00:00  0.469\" -> two spaces? Actually, it's hard to tell. We'll use one space.\n\n  But the example input in the problem uses:\n\n        \"2017-04-03 00:00:00  0.469\"\n\n  So we'll use two spaces.\n\n  We'll write:\n\n        [date string]  [value]\n\n  with two spaces.\n\n  Let's do it.\n\n  We have the 24 values for a day:\n\n      values = [0.369, 0.536, 0.955, 0.603, 0.402, 0.536, 0.201, 0.151, 0.821, 0.770, 1.223, 1.088, -0.168, 1.206, 0.938, 0.017, -0.637, -0.536, -1.206, -1.273, -1.189, -1.457, -0.670, 0.184]\n\n  Then for each day in the next 4 days, we assign these values.\n\n  We generate the dates:\n\n      Day1: 2017-04-07\n      Day2: 2017-04-08\n      Day3: 2017-04-09\n      Day4: 2017-04-10\n\n  For each day, we iterate from hour0 to hour23.\n\n  We must be cautious: the date format is YYYY-MM-DD HH:MM:SS, with two digits for hour, minute, second.\n\n  The input had: hour:minute:second as 00:00:00, 01:00:00, etc.\n\n  We'll write:\n\n      for day_offset in [0,1,2,3]:\n          base_date = (2017,4,7) + day_offset days -> but we have to account for month change? \n          Actually, April has 30 days.\n\n          Day0: 2017-04-07\n          Day1: 2017-04-08\n          Day2: 2017-04-09\n          Day3: 2017-04-10\n\n      For each hour in 0..23:\n          date_str = f\"2017-04-{7+day_offset:02d} {hour:02d}:00:00\"\n\n  But note: 7,8,9,10: \n        7 -> \"07\",  But 8 -> \"08\", 9->\"09\", 10->\"10\"\n\n  So we can do:\n\n        for day in [7,8,9,10]:\n            for hour in range(24):\n                date_str = \"2017-04-{:02d} {:02d}:00:00\".format(day, hour)\n\n  But wait: 2017-04-07 to 2017-04-10: \n        day 7: 2017-04-07\n        day 8: 2017-04-08\n        day 9: 2017-04-09\n        day 10: 2017-04-10\n\n  Then we assign the value = values[hour]\n\n  So we write 96 lines.\n\n  We'll write the answer in the format:\n\n      <answer>\n        2017-04-07 00:00:00  0.369\n        2017-04-07 01:00:00  0.536\n        ... \n        2017-04-10 23:00:00  0.184\n      </answer>\n\n  But note: the problem says \"remember to give me the complete data\" and \"You mustn't omit any content\".\n\n  We are providing 96 lines.\n\n  Let's double-check: 4 days * 24 = 96.\n\n  We are done.\n\n  However, note: the problem says the data has missing values? We are not given any in the history, and we are forecasting without missing.\n\n  We are using a very simple method because of the short history.\n\n  If we had more data, we could use a more sophisticated model. But with 4 days, this is reasonable.\n\n  We output the data.\n\n  Note: The problem says \"Please obey the format strictly\". The format is:\n\n        <answer>\n        \n        ...\n\n        </answer>\n\n  And the content is the data in the same format as the input (without the index numbers).\n\n  We write:\n\n        date   HULL\n        [then the data]\n\n  But the input example did not have a header in the data part? The input example had:\n\n        \"2017-04-03 00:00:00  0.469\"\n\n  without a header in the data lines. The header was given once at the top.\n\n  However, the problem says: \"I will now give you data for the past 96 recorded dates\" and then listed the data without header.\n\n  So in the answer, we only output the data lines (without the header).\n\n  But the problem says: \"Please give me the complete data for the next 96 recorded dates\"\n\n  So we output 96 lines of data.\n\n  We do not output the header again.\n\n  The example output format:\n\n        <answer>\n        \n        2017-04-07 00:00:00  0.369\n        2017-04-07 01:00:00  0.536\n        ... \n        2017-04-10 23:00:00  0.184\n        \n        </answer>\n\n  We'll do that.\n\n  Let's write the data.\n",
        "answer": "<answer>\n\n2017-04-07 00:00:00  0.369\n2017-04-07 01:00:00  0.536\n2017-04-07 02:00:00  0.955\n2017-04-07 03:00:00  0.603\n2017-04-07 04:00:00  0.402\n2017-04-07 05:00:00  0.536\n2017-04-07 06:00:00  0.201\n2017-04-07 07:00:00  0.151\n2017-04-07 08:00:00  0.821\n2017-04-07 09:00:00  0.770\n2017-04-07 10:00:00  1.223\n2017-04-07 11:00:00  1.088\n2017-04-07 12:00:00  -0.168\n2017-04-07 13:00:00  1.206\n2017-04-07 14:00:00  0.938\n2017-04-07 15:00:00  0.017\n2017-04-07 16:00:00  -0.637\n2017-04-07 17:00:00  -0.536\n2017-04-07 18:00:00  -1.206\n2017-04-07 19:00:00  -1.273\n2017-04-07 20:00:00  -1.189\n2017-04-07 21:00:00  -1.457\n2017-04-07 22:00:00  -0.670\n2017-04-07 23:00:00  0.184\n2017-04-08 00:00:00  0.369\n2017-04-08 01:00:00  0.536\n2017-04-08 02:00:00  0.955\n2017-04-08 03:00:00  0.603\n2017-04-08 04:00:00  0.402\n2017-04-08 05:00:00  0.536\n2017-04-08 06:00:00  0.201\n2017-04-08 07:00:00  0.151\n2017-04-08 08:00:00  0.821\n2017-04-08 09:00:00  0.770\n2017-04-08 10:00:00  1.223\n2017-04-08 11:00:00  1.088\n2017-04-08 12:00:00  -0.168\n2017-04-08 13:00:00  1.206\n2017-04-08 14:00:00  0.938\n2017-04-08 15:00:00  0.017\n2017-04-08 16:00:00  -0.637\n2017-04-08 17:00:00  -0.536\n2017-04-08 18:00:00  -1.206\n2017-04-08 19:00:00  -1.273\n2017-04-08 20:00:00  -1.189\n2017-04-08 21:00:00  -1.457\n2017-04-08 22:00:00  -0.670\n2017-04-08 23:00:00  0.184\n2017-04-09 00:00:00  0.369\n2017-04-09 01:00:00  0.536\n2017-04-09 02:00:00  0.955\n2017-04-09 03:00:00  0.603\n2017-04-09 04:00:00  0.402\n2017-04-09 05:00:00  0.536\n2017-04-09 06:00:00  0.201\n2017-04-09 07:00:00  0.151\n2017-04-09 08:00:00  0.821\n2017-04-09 09:00:00  0.770\n2017-04-09 10:00:00  1.223\n2017-04-09 11:00:00  1.088\n2017-04-09 12:00:00  -0.168\n2017-04-09 13:00:00  1.206\n2017-04-09 14:00:00  0.938\n2017-04-09 15:00:00  0.017\n2017-04-09 16:00:00  -0.637\n2017-04-09 17:00:00  -0.536\n2017-04-09 18:00:00  -1.206\n2017-04-09 19:00:00  -1.273\n2017-04-09 20:00:00  -1.189\n2017-04-09 21:00:00  -1.457\n2017-04-09 22:00:00  -0.670\n2017-04-09 23:00:00  0.184\n2017-04-10 00:00:00  0.369\n2017-04-10 01:00:00  0.536\n2017-04-10 02:00:00  0.955\n2017-04-10 03:00:00  0.603\n2017-04-10 04:00:00  0.402\n2017-04-10 05:00:00  0.536\n2017-04-10 06:00:00  0.201\n2017-04-10 07:00:00  0.151\n2017-04-10 08:00:00  0.821\n2017-04-10 09:00:00  0.770\n2017-04-10 10:00:00  1.223\n2017-04-10 11:00:00  1.088\n2017-04-10 12:00:00  -0.168\n2017-04-10 13:00:00  1.206\n2017-04-10 14:00:00  0.938\n2017-04-10 15:00:00  0.017\n2017-04-10 16:00:00  -0.637\n2017-04-10 17:00:00  -0.536\n2017-04-10 18:00:00  -1.206\n2017-04-10 19:00:00  -1.273\n2017-04-10 20:00:00  -1.189\n2017-04-10 21:00:00  -1.457\n2017-04-10 22:00:00  -0.670\n2017-04-10 23:00:00  0.184\n\n</answer>"
    }
]